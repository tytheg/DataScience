{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".h1_cell, .just_text {\n",
       "    box-sizing: border-box;\n",
       "    padding-top:5px;\n",
       "    padding-bottom:5px;\n",
       "    font-family: \"Times New Roman\", Georgia, Serif;\n",
       "    font-size: 125%;\n",
       "    line-height: 22px; /* 5px +12px + 5px */\n",
       "    text-indent: 25px;\n",
       "    background-color: #fbfbea;\n",
       "    padding: 10px;\n",
       "}\n",
       "\n",
       "hr { \n",
       "    display: block;\n",
       "    margin-top: 0.5em;\n",
       "    margin-bottom: 0.5em;\n",
       "    margin-left: auto;\n",
       "    margin-right: auto;\n",
       "    border-style: inset;\n",
       "    border-width: 2px;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".h1_cell, .just_text {\n",
    "    box-sizing: border-box;\n",
    "    padding-top:5px;\n",
    "    padding-bottom:5px;\n",
    "    font-family: \"Times New Roman\", Georgia, Serif;\n",
    "    font-size: 125%;\n",
    "    line-height: 22px; /* 5px +12px + 5px */\n",
    "    text-indent: 25px;\n",
    "    background-color: #fbfbea;\n",
    "    padding: 10px;\n",
    "}\n",
    "\n",
    "hr { \n",
    "    display: block;\n",
    "    margin-top: 0.5em;\n",
    "    margin-bottom: 0.5em;\n",
    "    margin-left: auto;\n",
    "    margin-right: auto;\n",
    "    border-style: inset;\n",
    "    border-width: 2px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<center>\n",
    "Final Project\n",
    "</center>\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "The goal of this project is to develop a program that will take a sentence and complete it with the gothic comax we developed in a past assignment. The first step is to import the needed libraries, the gothic table, and make the comax. For this project I modified our comax code so as to only take in the following words, not the previous and following. Once this is done we can see the list of words that follow a given word in our comax.\n",
    "</div>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "We will need the sentence wrangler and all of the necessary parts as well as the comax method.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gothic_table = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vQqRwyE0ceZREKqhuaOw8uQguTG6Alr5kocggvAnczrWaimXE8ncR--GC0o_PyVDlb-R6Z60v-XaWm9/pub?output=csv',\n",
    "                          encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gothic_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_wrangler(sentence, swords, punctuation):\n",
    "    good_words = []\n",
    "    bad_words = []\n",
    "    word_tokes = word_punct_tokenizer.tokenize(sentence)\n",
    "    for word in word_tokes:\n",
    "        word = word.lower()\n",
    "        if any(char in punctuation for char in word):\n",
    "            bad_words.append(word)\n",
    "        elif (word in swords):\n",
    "            bad_words.append(word)\n",
    "        else:\n",
    "            good_words.append(word)\n",
    "    return(good_words, bad_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context():\n",
    "    d = sorted(list(bag_of_words.keys()))\n",
    "    comax = pd.DataFrame(0, columns=d, index=d)\n",
    "    for i in range(0,len(gothic_table)):\n",
    "        idx = 0\n",
    "        row = gothic_table.iloc[i]\n",
    "        tup = sentence_wrangler(row['text'], swords, punctuation)\n",
    "        words = tup[0]\n",
    "        for j in range(0, len(words)):\n",
    "            if j == len(words)-1:\n",
    "                break;\n",
    "            else:\n",
    "                comax.loc[words[j+1], words[j]] += 1\n",
    "    return comax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "swords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "word_punct_tokenizer = WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "legals = r'[a-zA-Z]+'\n",
    "bag_of_words = json.load(open(\"bag_of_words.txt\"))\n",
    "\n",
    "import string\n",
    "import re\n",
    "punctuation = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "comax = context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaem</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abaft</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abaout</th>\n",
       "      <th>abased</th>\n",
       "      <th>...</th>\n",
       "      <th>æneid</th>\n",
       "      <th>ærial</th>\n",
       "      <th>æronaut</th>\n",
       "      <th>æronauts</th>\n",
       "      <th>ærostation</th>\n",
       "      <th>æschylus</th>\n",
       "      <th>élite</th>\n",
       "      <th>émeutes</th>\n",
       "      <th>οἶδα</th>\n",
       "      <th>υπνοσ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaem</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aback</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abaft</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24944 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         aaem  ab  aback  abaft  abandon  abandoned  abandoning  abandonment  \\\n",
       "aaem        0   0      0      0        0          0           0            0   \n",
       "ab          0   0      0      0        0          0           0            0   \n",
       "aback       0   0      0      0        0          0           0            0   \n",
       "abaft       0   0      0      0        0          0           0            0   \n",
       "abandon     0   0      0      0        0          0           0            0   \n",
       "\n",
       "         abaout  abased  ...    æneid  ærial  æronaut  æronauts  ærostation  \\\n",
       "aaem          0       0  ...        0      0        0         0           0   \n",
       "ab            0       0  ...        0      0        0         0           0   \n",
       "aback         0       0  ...        0      0        0         0           0   \n",
       "abaft         0       0  ...        0      0        0         0           0   \n",
       "abandon       0       0  ...        0      0        0         0           0   \n",
       "\n",
       "         æschylus  élite  émeutes  οἶδα  υπνοσ  \n",
       "aaem            0      0        0     0      0  \n",
       "ab              0      0        0     0      0  \n",
       "aback           0      0        0     0      0  \n",
       "abaft           0      0        0     0      0  \n",
       "abandon         0      0        0     0      0  \n",
       "\n",
       "[5 rows x 24944 columns]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = comax['monster'].sum()\n",
    "num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "<center>\n",
    "Find common words\n",
    "</center>\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "The next step is to write a function that will return a list of words sorted by the frequency the word occurs after a given word. This will give us a good idea of the words that often follow a certain word in our database.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def following(word, data):\n",
    "    headers = list(data)\n",
    "    ml = []\n",
    "    for i in range(len(data)):\n",
    "        frame = data[word]\n",
    "        if (frame.loc[headers[i]] > 0):\n",
    "            ml.append((headers[i], frame.loc[headers[i]]))\n",
    "    ml.sort(key=lambda x: x[1], reverse=True)\n",
    "    return ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'really', 2), (u'seen', 2), (u'already', 1), (u'beneath', 1), (u'bestowed', 1), (u'blot', 1), (u'bootleg', 1), (u'committed', 1), (u'continued', 1), (u'dared', 1), (u'drink', 1), (u'executed', 1), (u'feared', 1), (u'fiend', 1), (u'filled', 1), (u'form', 1), (u'former', 1), (u'held', 1), (u'hovered', 1), (u'labyrinth', 1), (u'let', 1), (u'make', 1), (u'malign', 1), (u'must', 1), (u'nightmares', 1), (u'none', 1), (u'possessed', 1), (u'said', 1), (u'saw', 1), (u'seemed', 1), (u'seized', 1), (u'still', 1), (u'symbol', 1), (u'ugly', 1), (u'vaguely', 1), (u'would', 1)]\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "l = following('monster', comax)\n",
    "print l\n",
    "print len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'beloved', 2), (u'creature', 2), (u'gay', 2), (u'happy', 2), (u'never', 2), (u'one', 2), (u'thoughts', 2), (u'beheld', 1), (u'beyond', 1), (u'bird', 1), (u'cheerful', 1), (u'chosen', 1), (u'circle', 1), (u'cognizant', 1), (u'conclusion', 1), (u'cottages', 1), (u'couple', 1), (u'cultivate', 1), (u'dandy', 1), (u'days', 1), (u'dear', 1), (u'dreamers', 1), (u'earth', 1), (u'evenings', 1), (u'excellent', 1), (u'fashion', 1), (u'father', 1), (u'feeding', 1), (u'feel', 1), (u'feelings', 1), (u'felt', 1), (u'find', 1), (u'first', 1), (u'folk', 1), (u'found', 1), (u'gentlewoman', 1), (u'get', 1), (u'glad', 1), (u'gods', 1), (u'grovel', 1), (u'harbour', 1), (u'harmless', 1), (u'health', 1), (u'home', 1), (u'however', 1), (u'human', 1), (u'inanimate', 1), (u'kind', 1), (u'knew', 1), (u'labours', 1), (u'let', 1), (u'life', 1), (u'little', 1), (u'longer', 1), (u'love', 1), (u'make', 1), (u'meet', 1), (u'might', 1), (u'moment', 1), (u'months', 1), (u'mothers', 1), (u'must', 1), (u'near', 1), (u'nurslings', 1), (u'obliterated', 1), (u'omen', 1), (u'others', 1), (u'perhaps', 1), (u'possessed', 1), (u'prosperous', 1), (u'recesses', 1), (u'remark', 1), (u'resting', 1), (u'revellers', 1), (u'security', 1), (u'serene', 1), (u'serenity', 1), (u'shall', 1), (u'sic', 1), (u'situation', 1), (u'smiles', 1), (u'take', 1), (u'thought', 1), (u'thrice', 1), (u'time', 1), (u'tomb', 1), (u'town', 1), (u'tranquil', 1), (u'ungrateful', 1), (u'unspeakably', 1), (u'valley', 1), (u'virtuous', 1), (u'weeks', 1), (u'weep', 1), (u'women', 1)]\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "l = following('happy', comax)\n",
    "print l\n",
    "print len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'loving', 1), (u'side', 1)]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "l = following('fawn', comax)\n",
    "print l\n",
    "print len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'father', 4), (u'one', 3), (u'elizabeth', 2), (u'friend', 2), (u'friends', 2), (u'girl', 2), (u'husband', 2), (u'perdita', 2), (u'sister', 2), (u'sole', 2), (u'although', 1), (u'athenians', 1), (u'august', 1), (u'awake', 1), (u'castle', 1), (u'child', 1), (u'cottagers', 1), (u'country', 1), (u'dead', 1), (u'dear', 1), (u'drooping', 1), (u'embrace', 1), (u'equals', 1), (u'eugenie', 1), (u'eye', 1), (u'eyes', 1), (u'fear', 1), (u'female', 1), (u'forest', 1), (u'girls', 1), (u'gone', 1), (u'grave', 1), (u'hands', 1), (u'happy', 1), (u'hard', 1), (u'heart', 1), (u'hour', 1), (u'idris', 1), (u'ill', 1), (u'ionian', 1), (u'joyous', 1), (u'lay', 1), (u'lessons', 1), (u'let', 1), (u'make', 1), (u'pride', 1), (u'puppy', 1), (u'raymond', 1), (u'reap', 1), (u'recess', 1), (u'remained', 1), (u'safie', 1), (u'sorrow', 1), (u'spoke', 1), (u'sympathizing', 1), (u'task', 1), (u'tomb', 1), (u'turned', 1), (u'una', 1), (u'venerable', 1), (u'voice', 1), (u'waist', 1), (u'walls', 1), (u'wretched', 1), (u'yet', 1)]\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "l = following('beloved', comax)\n",
    "print l\n",
    "print len(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "<center>\n",
    "Basic Auto Complete\n",
    "</center>\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Now we need to write a function that will take a sentence and complete it with the words we found. This function will take in a sentence that needs to be completed, the comax, and the number of words you want to complete the sentence. This won't take into account what might make the sentence more likely to be correct, and instead just add the words on and return the sentence. To add to it the function will return 2 sentences, each with different word options from the list, in case one returns a better result.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_complete(sentence, data, num):\n",
    "    sentencea = sentence\n",
    "    sentenceb = sentence\n",
    "    words = sentence_wrangler(sentence, swords, punctuation)\n",
    "    word = words[0][-1]\n",
    "    for i in range(num):\n",
    "        w = following(word, data)\n",
    "        sentencea += ' ' + w[0][0]\n",
    "        word = w[0][0]\n",
    "    word = words[0][-1]\n",
    "    for i in range(num):\n",
    "        w = following(word, data)\n",
    "        sentenceb += ' ' + w[1][0]\n",
    "        word = w[1][0]\n",
    "    return (sentencea, sentenceb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'Frankenstein is a happy beloved', u'Frankenstein is a happy creature')"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_complete('Frankenstein is a happy', comax, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'My friend is a sad solemn bells', u'My friend is a sad affair attention')"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_complete('My friend is a sad', comax, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'I punch bowl certain things', u'I punch fire place since')"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_complete('I punch', comax, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'I like some one day day day day',\n",
       " u'I like some things old woman fanged bearded')"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_complete('I like some', comax, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "We can se that some of the sentences make sense somewhat, but as we go further with the autocomplete, the sentences often make less sense. Next we make some assumptions to try and make it more effective by giving the user control to choose the part of speech to add.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "nouns = {x.name().split('.', 1)[0] for x in wn.all_synsets('n')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_verb(sentence, data):\n",
    "    sents = []\n",
    "    words = sentence_wrangler(sentence, swords, punctuation)\n",
    "    word = words[0][-1]\n",
    "    f = following(word, comax)\n",
    "    w = [i[0] for i in f]\n",
    "    verbs = []\n",
    "    for i in range(len(w)):\n",
    "        p = nltk.word_tokenize(w[i])\n",
    "        data_pos = nltk.tag.pos_tag(p) #POS tagging\n",
    "        if data_pos[0][1][0] == 'V':\n",
    "            verbs.append(data_pos[0][0])\n",
    "    for wd in verbs:\n",
    "        sents.append((sentence + ' ' + wd))\n",
    "    \n",
    "    return sents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'I like to know',\n",
       " u'I like to take',\n",
       " u'I like to hissing',\n",
       " u'I like to remembered',\n",
       " u'I like to seen']"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_verb('I like to', comax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'It scared me when frankenstein discovered',\n",
       " u'It scared me when frankenstein dozing',\n",
       " u'It scared me when frankenstein said']"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_verb('It scared me when frankenstein', comax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "It seems like we can improve this autocorrect by adding a noun to the end of the words. We can change the add_verb method to add a noun instead\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noun(sentence, data):\n",
    "    sents = []\n",
    "    words = sentence_wrangler(sentence, swords, punctuation)\n",
    "    word = words[0][-1]\n",
    "    f = following(word, comax)\n",
    "    w = [i[0] for i in f]\n",
    "    nouns = []\n",
    "    for i in range(len(w)):\n",
    "        p = nltk.word_tokenize(w[i])\n",
    "        data_pos = nltk.tag.pos_tag(p) #POS tagging\n",
    "        if data_pos[0][1][0] == 'N':\n",
    "            nouns.append(data_pos[0][0])\n",
    "    for wd in nouns:\n",
    "        sents.append((sentence + ' ' + wd))\n",
    "    \n",
    "    return sents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'I like the things',\n",
       " u'I like the child',\n",
       " u'I like the elephant',\n",
       " u'I like the light',\n",
       " u'I like the something']"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_noun('I like the', comax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "<center>\n",
    "Auto-complete with chosen part of speech\n",
    "</center>\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "The best way to handle this is to give the user the choice of what part of speech they want to add to their gothic sentence\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_POS(sentence, data, pos):\n",
    "    sents = []\n",
    "    words = sentence_wrangler(sentence, swords, punctuation)\n",
    "    word = words[0][-1]\n",
    "    f = following(word, comax)\n",
    "    w = [i[0] for i in f]\n",
    "    potentials = []\n",
    "    for i in range(len(w)):\n",
    "        p = nltk.word_tokenize(w[i])\n",
    "        data_pos = nltk.tag.pos_tag(p) #POS tagging\n",
    "        if data_pos[0][1] == pos:\n",
    "            potentials.append(data_pos[0][0])\n",
    "    for wd in potentials:\n",
    "        sents.append((sentence + ' ' + wd))\n",
    "    \n",
    "    return sents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'I like the child',\n",
       " u'I like the elephant',\n",
       " u'I like the light',\n",
       " u'I like the something',\n",
       " u'I like the spirit']"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_POS('I like the', comax, 'NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'I think frankenstein said dupin',\n",
       " u'I think frankenstein said raymond',\n",
       " u'I think frankenstein said ryland',\n",
       " u'I think frankenstein said friend',\n",
       " u'I think frankenstein said legrand']"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'I think frankenstein'\n",
    "first = add_POS(sentence, comax, 'VBD')\n",
    "add_POS(first[0], comax, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "<center>\n",
    "    Conclusion\n",
    "</center>\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Giving the user the option to choose what part of speech they want to add is a good way to try and make sure the sentence will make sense. While it isn't perfect, as long as there are some parts of speech that follow it in our comax, we will be able to produce solid sentences.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
